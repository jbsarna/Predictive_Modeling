---
title: "Regression Models"
author: "Justin Sarna"
date: "April 20, 2017"
version: "Final"
output: html_document

GitHub: https://github.com/jbsarna/Predictive_Modeling/blob/master/regression_models.Rmd
---

```{r}
acs <- read.table("http://jaredlander.com/data/acs_ny.csv",sep=",",
                  header=TRUE, stringsAsFactors=TRUE)
```
```{r}
# Load the necessary libraries
library(ggplot2)
library(useful)
library(caret)
library(ISLR)
library(scales)
library(plyr)
library(rpart)
library(rpart.plot)
library(class)
library(MuMIn)
library(caret)
library(dplyr)
library(RColorBrewer)
library(randomForest)
library(kernlab)
library(nlme)
library(lme4)
library(mgcv)
```
# Create new variables based on EDA
```{r}
# code from hw4 to be used for creating additional models
acs$HighIncome <- as.numeric(with(acs, FamilyIncome >= 250000))
acs$foodstamp_binary <- ifelse(acs$FoodStamp == "Yes",1,0) # (yes = 1, no = 0)
acs$own_home <- ifelse(acs$OwnRent == "Rented",0, ifelse(acs$FamilyIncome == "Mortgage",1,2)) # (own = 1, rent = 0)
acs$family_type_cat <- ifelse(acs$FamilyType == "Married",1, ifelse(acs$FamilyIncome == "Female Head",2,3))

# married = 1, male head = 2, female head = 3
acs$InsuranceHigh <- (acs$Insurance > 1000) * 1
acs$NumWorkers2 <- (acs$NumWorkers == 2) * 1
acs$HouseCostsHigh <- (acs$HouseCosts > 1000) * 1
acs$high_electric <- (acs$ElectricBill > 350) * 1

# Create binary variable where 1 = not on food stamps & not renting & married
acs$HI_pred1[acs$FoodStamp == 'No' & acs$OwnRent != 'Rented' & acs$FamilyType == 'Married'] <- 1

# Break it into a training and test set with an 80/20 split.
set.seed(447)
testrecs <- sample(nrow(acs),0.2 * nrow(acs))
acs_test <- acs[testrecs,]
acs_fit <- acs[-testrecs,]
```

Let's start by building a *null* model in which you simply predict that everyone's
income is < 250000 (since the majority of incomes are less than 250000).

## Null Model for model comparison

```{r}
acs$null_model <- 0
```

Create a confusion matrix table and compute the overall accuracy of this model as well as its sensitivity and specificity.

```{r}
table(acs$HighIncome, acs$null_model)

prop.table(table(acs$HighIncome, acs$null_model))

confusionMatrix(as.factor(acs$null_model), as.factor(acs$HighIncome), positive = "1")
```

# Logistic Regression

1) Specify the model
2) Show summary results
3) Predict using model
4) Set binomial variable equal to predictions with criteria > .5
5) Set variable = AIC
6) Confusion matrix
7) Display confusion matrix

#### logistic regression model 1

```{r}
logmod1 <- glm(HighIncome ~ FamilyType + NumVehicles + OwnRent + Insurance + YearBuilt, data=acs_fit, 
               family=binomial(link="logit"))

summary(logmod1)

acs_test$yhat_logmod1 <- predict(logmod1, newdata=acs_test, type='response')

acs_test$yhat_logmod1 <- (acs_test$yhat_logmod1 > 0.05) * 1

log_mod1_aic <- summary(logmod1)$aic

log_cm1 <- confusionMatrix(as.factor(acs_test$yhat_logmod1), as.factor(acs_test$HighIncome), positive = "1")

log_cm1
```
#### logistic regression model 2

```{r}
logmod2 <- glm(HighIncome ~ FamilyType + FoodStamp + OwnRent, data=acs_fit, family=binomial(link="logit"))

summary(logmod2)

acs_test$yhat_logmod2 <- predict(logmod2, newdata=acs_test, type='response')

acs_test$yhat_logmod2 <- (acs_test$yhat_logmod2 > 0.05) * 1

log_mod2_aic <- summary(logmod2)$aic

log_cm2 <- confusionMatrix(as.factor(acs_test$yhat_logmod2), as.factor(acs_test$HighIncome), positive = "1")

log_cm2
```
#### logistic regression model 3

```{r}
logmod3 <- glm(HighIncome ~ InsuranceHigh + NumWorkers2 + HouseCostsHigh + FoodStamp + OwnRent, 
               data=acs_fit, family=binomial(link="logit"))

summary(logmod3)

acs_test$yhat_logmod3 <- predict(logmod3, newdata=acs_test, type='response')

acs_test$yhat_logmod3 <- (acs_test$yhat_logmod3 > 0.05) * 1

log_mod3_aic <- summary(logmod3)$aic

log_cm3 <- confusionMatrix(as.factor(acs_test$yhat_logmod3), as.factor(acs_test$HighIncome), positive = "1")

log_cm3
```
#### logistic regression model 4

```{r}
logmod4 <- glm(HighIncome ~ InsuranceHigh + NumWorkers2 + HouseCostsHigh, data=acs_fit, family=binomial(link="logit"))

summary(logmod4)

acs_test$yhat_logmod4 <- predict(logmod4, newdata=acs_test, type='response')

acs_test$yhat_logmod4 <- (acs_test$yhat_logmod4 > 0.05) * 1

log_mod4_aic <- summary(logmod4)$aic

log_cm4 <- confusionMatrix(as.factor(acs_test$yhat_logmod4), as.factor(acs_test$HighIncome), positive = "1")

log_cm4
```
#### logistic regression model 5

```{r}
logmod5 <- glm(HighIncome ~ FamilyType + NumBedrooms + NumChildren + NumPeople + NumRooms + NumUnits + NumVehicles + 
                 NumWorkers + OwnRent + HouseCosts + ElectricBill + FoodStamp + Insurance + Language + 
                 InsuranceHigh + NumWorkers2 + HouseCostsHigh, data=acs_fit, family=binomial(link="logit"))

summary(logmod5)

acs_test$yhat_logmod5 <- predict(logmod5, newdata=acs_test, type='response')

acs_test$yhat_logmod5 <- (acs_test$yhat_logmod5 > 0.05) * 1

log_mod5_aic <- summary(logmod5)$aic

log_cm5 <- confusionMatrix(as.factor(acs_test$yhat_logmod5), as.factor(acs_test$HighIncome), positive = "1")

log_cm5
```

#### logistic regression model 6

```{r}
logmod6 <- glm(HighIncome ~ FamilyType + NumBedrooms + NumChildren + OwnRent + 
              HouseCosts + ElectricBill + FoodStamp + InsuranceHigh, 
              data=acs_fit, family=binomial(link="logit"))

summary(logmod6)

acs_test$yhat_logmod6 <- predict(logmod6, newdata=acs_test, type='response')

acs_test$yhat_logmod6 <- (acs_test$yhat_logmod6 > 0.05) * 1

log_mod6_aic <- summary(logmod6)$aic

log_cm6 <- confusionMatrix(as.factor(acs_test$yhat_logmod6), as.factor(acs_test$HighIncome), positive = "1")

log_cm6
```

# Linear Regression

1) Specify the model
2) Show summary results
3) Predict using model
4) Set binomilal variable equal to predictions with criteria > 250000
5) Set variable = r squared
5) Set variable = AIC
6) Confusion matrix
7) Display confusion matrix

#### Linear regression model 1

```{r}
linear_mod1 <- lm(FamilyIncome ~ FamilyType + FoodStamp + OwnRent + HouseCosts + Insurance + ElectricBill + 
                    NumRooms, data=acs_fit)

summary(linear_mod1)

acs_test$lin_mod1_FamilyIncome <- predict(linear_mod1, newdata=acs_test)

acs_test$lin_mod1_HighIncome <- ifelse(acs_test$lin_mod1_FamilyIncome > 250000,1,0)

linear_mod1_rsq <- summary(linear_mod1)$r.sq

linear_mod1_aic <- AIC(linear_mod1)

linear_cm1 <- confusionMatrix(as.factor(acs_test$lin_mod1_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

linear_cm1

# Residual Analysis
summary(acs_test$HighIncome - predict(linear_mod1,newdata=acs_test))
```

#### Linear regression model 2

```{r}
linear_mod2 <- lm(FamilyIncome ~ Insurance + HouseCosts + ElectricBill + NumWorkers + FamilyType + 
                    FoodStamp + OwnRent + NumBedrooms + NumChildren + NumRooms + NumPeople + 
                    NumVehicles + Language, data=acs_fit)

summary(linear_mod2)

acs_test$lin_mod2_FamilyIncome <- predict(linear_mod2, newdata=acs_test)

acs_test$lin_mod2_HighIncome <- ifelse(acs_test$lin_mod2_FamilyIncome > 250000,1,0)

linear_mod2_rsq <- summary(linear_mod2)$r.sq

linear_mod2_aic <- AIC(linear_mod2)

linear_cm2 <- confusionMatrix(as.factor(acs_test$lin_mod2_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

linear_cm2

# Residual Analysis
summary(acs_test$HighIncome - predict(linear_mod2,newdata=acs_test))
```

# Support Vector Machines

"Finds the line/plane/hyperplane that separates the two groups of data as much as possible, and then see which side the new data points land on." click the link below to see rest of SVM explanation. They give two great examples in simple terms in this forum:

https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/

## SVM process

1) Specify the model
2) Predict using model
4) Set binomial variable equal to predictions with probability greater than 50%
7) Confusion matrix
5) Display confusion matrix

#### SVM model 1

```{r}
svm_mod1 <- ksvm(HighIncome ~ Insurance + HouseCosts + ElectricBill + FamilyType + OwnRent + NumVehicles + NumBedrooms + 
                NumWorkers + NumPeople + NumChildren + NumUnits + FoodStamp + YearBuilt + Language + HeatingFuel, 
                data=acs_fit, family=binomial(link="logit"))

acs_test$svm_HighIncome <- predict(svm_mod1, newdata=acs_test, type='response')

acs_test$svm_HighIncome <- (acs_test$svm_HighIncome > 0.5) * 1

svm_cm1 <- confusionMatrix(as.factor(acs_test$svm_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

svm_cm1

# Residual Analysis
summary(acs_test$HighIncome - predict(svm_mod1,newdata=acs_test))
```

#### SVM model 2

```{r}
svm_mod2 <- ksvm(FamilyIncome ~ Insurance + HouseCosts + ElectricBill + FamilyType + OwnRent + NumVehicles + NumBedrooms, 
                 data=acs_fit)

acs_test$svm2_HighIncome <- predict(svm_mod2, newdata=acs_test)

acs_test$svm2_HighIncome <- ifelse(acs_test$svm2_HighIncome > 250000,1,0)

svm_cm2 <- confusionMatrix(as.factor(acs_test$svm2_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

svm_cm2

# Residual Analysis
summary(acs_test$HighIncome - predict(svm_mod2,newdata=acs_test))
```

#### SVM model 3

```{r}
svm_mod3 <- ksvm(HighIncome ~ Insurance + HouseCosts + ElectricBill + FamilyType + OwnRent + NumRooms, data=acs_fit,
                 family=binomial(link="logit"))

acs_test$svm3_HighIncome <- predict(svm_mod3, newdata=acs_test, type='response')

acs_test$svm3_HighIncome <- (acs_test$svm3_HighIncome > 0.5) * 1

svm_cm3 <- confusionMatrix(as.factor(acs_test$svm3_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

svm_cm3

# Residual Analysis
summary(acs_test$HighIncome - predict(svm_mod3,newdata=acs_test))
```

# Multilevel Model Specification

"A mixed model is similar in many ways to a linear model. It estimates the effects of one or more explanatory variables on a response variable. The output of a mixed model will give you a list of explanatory values, estimates and confidence intervals of their effect sizes, p-values for each effect, and at least one measure of how well the model fits. You should use a mixed model instead of a simple linear model when you have a variable that describes your data sample as a subset of the data you could have collected" Tufts.edu (see link for source of quote)

Check out this link for a very well explained tutorial with easy to understand explanation of mixed models:

http://ase.tufts.edu/gsc/gradresources/guidetomixedmodelsinr/mixed%20model%20guide.html

I would not use this model for this data set to specify th

1) Specify model
2) Model summary
3) Predict
4) Transform predictions to binomial > .5
4) Confusion matrix
5) Display confusion matrix
6) Set variable = AIC
7) Display AIC


#### MMS model using lme()

```{r}
mms1 <- lme(HighIncome ~ Insurance + HouseCosts + ElectricBill + FoodStamp + 
            OwnRent, method = "ML", data = acs_fit, random =~ NumChildren | FamilyType)

summary(mms1)

acs_test$mms1_HighIncome <- predict(mms1, newdata=acs_test, type='response')

acs_test$mms1_HighIncome <- (acs_test$mms1_HighIncome > 0.5) * 1

mms1_cm <- confusionMatrix(as.factor(acs_test$mms1_HighIncome), as.factor(acs_test$HighIncome), positive = "1")
mms1_cm

mms1_aic <- AIC(mms1)
mms1_aic
```

#### MMS model using lmer()

```{r}
mms2 <- lmer(HighIncome ~ 1 + FoodStamp + OwnRent + FamilyType + OwnRent + NumWorkers + (1 | FamilyType), data = acs_fit)

summary(mms2)

acs_test$mms2_HighIncome <- predict(mms2, newdata=acs_test, type='response')
acs_test$mms2_HighIncome <- (acs_test$mms2_HighIncome > 0.5) * 1

mms2_cm <- confusionMatrix(as.factor(acs_test$mms2_HighIncome), as.factor(acs_test$HighIncome), positive = "1")
mms2_cm

mms2_aic <- AIC(mms2)
mms2_aic
```

# Generalized Additive Models

## Important considerations of GAM

GAM's let you represent nonlinear and non-montonic relationships between variables and outcome in linear or logistic regression framework

Evaluate the GAM with same measures as you would for simple linear or logistic regression.

Here is a good link with detailed explnation & a good code example:

https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/gam.html

### GAM model process

1) Specify model
2) Model summary
3) Predict using model
4) Use estimates to create binomial for High Income
5) Set variable = r squared
6) Set variable = AIC
7) Confusion matrix
8) Display confusion matrix
9) Residual analysis

#### GAM 1 - Estimating family income & use those estimates to predict High Income

```{r}
gam_mod1 <- gam(FamilyIncome ~ s(Insurance) + s(HouseCosts) + s(ElectricBill) + NumWorkers + FamilyType + 
                  FoodStamp + OwnRent + NumBedrooms + s(NumChildren) + s(NumRooms) + s(NumPeople) + NumVehicles + 
                  Language, family=gaussian(link =identity), data=acs_fit)

summary(gam_mod1)

acs_test$gam_FamilyIncome <- predict(gam_mod1, newdata=acs_test)

acs_test$gam_HighIncome <- ifelse(acs_test$gam_FamilyIncome > 250000,1,0)

gam_mod1_rsq <- summary(gam_mod1)$r.sq

gam_mod_aic <- AIC(gam_mod1)

gam_cm1 <- confusionMatrix(as.factor(acs_test$gam_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

gam_cm1

# Residual Analysis
summary(acs_test$HighIncome - predict(gam_mod1,newdata=acs_test))
```

#### GAM 2 - Use logistic model with GAM to predict High Income

```{r}
gam_mod2 <- gam(HighIncome ~ s(Insurance) + s(HouseCosts) + s(ElectricBill) + NumWorkers + FamilyType + FoodStamp + 
                  OwnRent + NumBedrooms + s(NumChildren) + s(NumRooms) + s(NumPeople) + NumVehicles + Language, 
                data = acs_fit, family=binomial(link="logit"))

summary(gam_mod2)

acs_test$gam2_HighIncome <- predict(gam_mod2, newdata=acs_test)

acs_test$gam2_HighIncome <- ifelse(acs_test$gam2_HighIncome > .5 ,1,0)

gam_mod2_rsq <- summary(gam_mod2)$r.sq

gam_mod2_aic <- AIC(gam_mod2)

gam_cm2 <- confusionMatrix(as.factor(acs_test$gam2_HighIncome), as.factor(acs_test$HighIncome), positive = "1")

gam_cm2

# Residual Analysis
summary(acs_test$HighIncome - predict(gam_mod2,newdata=acs_test))
```

#### Plot GAM model 2 tosvm_cm1 visualize the s() effect

```{r}
plot(gam_mod2)
```

# MuMIn and the wonders of the dredge() function!

This package automates the model specification process to some degree. It does so by "dredging" through all possible combinations of independent variables. You can then display "best models" and importance metrics, which can then be used to specify your model.

This link is a very detailed example of using MuMIn and the dredge function. Scsprintf("Logistic model 6: Predicted Accuracy = %.3f Predicted Sensitivity = %.3f AIC = %.1f", 
        
https://sites.google.com/site/rforfishandwildlifegrads/home/mumin_usage_examples

1) Specify Model
2) Dredge
3) Model Summary
4) Find best models
5) Calculate importance weights

## GLM dredge

```{r}
# be aware that this takes time to run. It is worth the wait BUT frowned upon when used due to spurious results and inference
dredge_glm_mod <- glm(HighIncome ~ Insurance + HouseCosts + ElectricBill + FamilyType + FoodStamp + OwnRent + 
              NumBedrooms + NumRooms, family=binomial(logit), na.action = "na.fail", data=acs_fit)

dd_glm <- dredge(dredge_glm_mod)
```
```{r}
summary(dredge_glm_mod)
```

```{r}
# best supported models
subset(dd_glm, delta < 5)

# best model
subset(dd_glm, delta == 0)

# calculate variable importance weights
importance(dd_glm)
```

#### LM dredge

```{r}
dredge_lm_mod <- lm(HighIncome ~ FamilyType + HouseCosts + Insurance + NumRooms + ElectricBill + FoodStamp + 
                      OwnRent + NumBedrooms, data = acs_fit, na.action = na.fail)

dd_lm <- dredge(dredge_lm_mod)

summary(dredge_lm_mod)

subset(dd_lm, delta < 5)

subset(dd_lm, delta == 0)

importance(dd_lm)
```

# Regression Model Comparison

List of all regression models

```{r}
sprintf("LOGISTIC REGRESSION")

sprintf("Logistic model 1: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm1$overall['Accuracy'], log_cm1$byClass['Sensitivity'], log_mod1_aic)

sprintf("Logistic model 2: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm2$overall['Accuracy'], log_cm2$byClass['Sensitivity'], log_mod2_aic)

sprintf("Logistic model 3: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm3$overall['Accuracy'], log_cm3$byClass['Sensitivity'], log_mod3_aic)

sprintf("Logistic model 4: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm4$overall['Accuracy'], log_cm4$byClass['Sensitivity'], log_mod4_aic)

sprintf("Logistic model 5: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm5$overall['Accuracy'], log_cm5$byClass['Sensitivity'], log_mod5_aic)

sprintf("Logistic model 6: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm6$overall['Accuracy'], log_cm6$byClass['Sensitivity'], log_mod6_aic)

sprintf("Logistic model 6: Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        log_cm6$overall['Accuracy'], log_cm6$byClass['Sensitivity'], log_mod6_aic)

sprintf("                                                                                        ")

sprintf("LINEAR REGRESSION")

sprintf("Linear model 1:   Predicted Accuracy = %.4f Predicted Sensitivity = %.3f Adj R-squared = %.3f", 
        linear_cm1$overall['Accuracy'], linear_cm1$byClass['Sensitivity'], linear_mod1_rsq)

sprintf("Linear model 2:   Predicted Accuracy = %.4f Predicted Sensitivity = %.3f Adj R-squared = %.3f", 
        linear_cm2$overall['Accuracy'], linear_cm2$byClass['Sensitivity'], linear_mod2_rsq)

sprintf("                                                                                        ")

sprintf("SUPPORT VECTOR MACHINES")

sprintf("SVM model 1:      Predicted Accuracy = %.4f Predicted Sensitivity = %.3f", 
        svm_cm1$overall['Accuracy'], svm_cm1$byClass['Sensitivity'])

sprintf("SVM model 2:      Predicted Accuracy = %.4f Predicted Sensitivity = %.3f", 
        svm_cm2$overall['Accuracy'], svm_cm2$byClass['Sensitivity'])

sprintf("SVM model 3:      Predicted Accuracy = %.4f Predicted Sensitivity = %.3f", 
        svm_cm3$overall['Accuracy'], svm_cm3$byClass['Sensitivity'])
sprintf("                                                                                        ")

sprintf("MULTILEVEL MODEL SPECIFICATION")

sprintf("MMS model 1:      Predicted Accuracy = NA    Predicted Sensitivity = NA    AIC = %.1f", mms1_aic)

sprintf("MMS model 2:      Predicted Accuracy = NA    Predicted Sensitivity = NA    AIC = %.1f", mms2_aic)

sprintf("                                                                                        ")

sprintf("GENERALIZED ADDITIVE MODELS")

sprintf("GAM model 1:      Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        gam_cm1$overall['Accuracy'], gam_cm1$byClass['Sensitivity'], gam_mod_aic)

sprintf("GAM model 2:      Predicted Accuracy = %.4f Predicted Sensitivity = %.3f AIC = %.1f", 
        gam_cm2$overall['Accuracy'], gam_cm2$byClass['Sensitivity'], gam_mod2_aic)
```

### Choose best model(s) and display formula

```{r}
formula(gam_mod2)
```

# Regression model decision & comments

1) My linear model does estimate negative incomes, which is not logically or stastically sound
    However, the purpose is to find best predictive model. So I ignored this to see how accurate I could predict High Income
    
2) Residual analysis of my best LM and best GAM models have a mean very far from 0, with quite a "large" range between min and max. This is not ideal, but for the purposes of stricly predicting as best as possible I can ignore this

3) Model comparisons
  + Many of the models have very close accuracy in predicting, and very similar sensitivity
  + Unfortunately all log models have very poor predicting accuracy because they have much higher sensitivity (good)
  + The linear models have highest sensitivity, with relatively high accuracy
  + Overall the SVM models have highest accuracy BUT also have low sensitivity

4) I would choose the SVM model 3 based on highest accuracy
