---
title: "cluster_analysis"
author: "Justin Sarna"
date: "April 14, 2017"
version: "Final"
output: html_document

GitHub: https://github.com/jbsarna/Predictive_Modeling/blob/master/cluster_analysis.Rmd
---

```{r}
acs <- read.table("http://jaredlander.com/data/acs_ny.csv",sep=",",
                  header=TRUE, stringsAsFactors=TRUE)
```

```{r}
# Load the necessary libraries
library(ggplot2)
library(useful)
library(caret)
library(ISLR)
library(scales)
library(plyr)
library(rpart)
library(rpart.plot)
library(class)
library(MuMIn)
library(caret)
library(dplyr)
library(RColorBrewer)
library(randomForest)
library(mgcv)
```
## Create some new variables based on EDA
1) This chunk of code is the same for all pages in this R-project
2) It is included in each rmd file so that you can examine each predictive method individually
3) See data_exploration for reasoning/logic
```{r}
# code from hw4 to be used for creating additional models
acs$HighIncome <- as.numeric(with(acs, FamilyIncome >= 250000))
acs$foodstamp_binary <- ifelse(acs$FoodStamp == "Yes",1,0) # (yes = 1, no = 0)
acs$own_home <- ifelse(acs$OwnRent == "Rented",0, ifelse(acs$FamilyIncome == "Mortgage",1,2)) # (own = 1, rent = 0)
acs$family_type_cat <- ifelse(acs$FamilyType == "Married",1, ifelse(acs$FamilyIncome == "Female Head",2,3))

# married = 1, male head = 2, female head = 3
acs$InsuranceHigh <- (acs$Insurance > 1000) * 1
acs$NumWorkers2 <- (acs$NumWorkers == 2) * 1
acs$HouseCostsHigh <- (acs$HouseCosts > 1000) * 1
acs$high_electric <- (acs$ElectricBill > 350) * 1

# Break it into a training and test set with an 80/20 split.
set.seed(447)
testrecs <- sample(nrow(acs),0.2 * nrow(acs))
acs_test <- acs[testrecs,]
acs_fit <- acs[-testrecs,]  

# Create binary variable where 1 = not on food stamps & not renting & married
acs$HI_pred1 <- 0
acs$HI_pred1[acs_test$FoodStamp == 'No' & acs_test$OwnRent != 'Rented' & acs_test$FamilyType == 'Married'] <- 1
acs$null_model <- 0
```

# Cluster Analysis

#### Function to normalize data

```{r}
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
```

## First cluster attempt

1) Create data frame
2) Normalize data
3) Calculate distances
4) Plot cluster dendogram
5) Cut the tree into k number of clusters

```{r}
acs_numericals2 <- data.frame(acs$HouseCosts, acs$ElectricBill, acs$Insurance)
acs_norm2 <- as.data.frame(lapply(acs_numericals2[1:3], normalize))
acs_norm2$FamilyType1 <- c(acs$FamilyType)

distance <- dist(acs_norm2, method ="euclidean")
pfit <- hclust(distance, method = "ward")

cluster1 <- plot(pfit, labels = acs_norm2$FamilyType)
rect.hclust(pfit, k=5)

acs_norm2$groups <- cutree(pfit, k=5)
```

#### Display each goup with number of observations per group

```{r}
table(acs_norm2$groups)
```

```{r}
# Add additional variables ot the data set for model specification
acs_norm2$HighIncome <- c(acs$HighIncome)
```
```{r}
# Break it into a training and test set with an 80/20 split.
set.seed(447)
testrecs <- sample(nrow(acs_norm2),0.2 * nrow(acs_norm2))
acs_norm2_test <- acs_norm2[testrecs,]
acs_norm2_fit <- acs_norm2[-testrecs,]  
```

## Use groups as new variable in model

#### Model with clusters

1) Specify model using GAM
2) Show summary of model
3) Set variable = r squared
4) Set variable = AIC
5) Set predictions to binomial based on criteria > .5
6) Confusion Matrix
7) Display confusion matrix, r squared, and AIC

```{r}
gam_mod_cluster <- gam(HighIncome ~ s(acs.Insurance) + s(acs.HouseCosts) + s(acs.ElectricBill) + groups, 
                data = acs_norm2_fit, family=binomial(link="logit"))

summary(gam_mod_cluster)

acs_norm2_test$gam_cluster_HighIncome <- predict(gam_mod_cluster, newdata=acs_norm2_test)

acs_norm2_test$gam_cluster_HighIncome <- ifelse(acs_norm2_test$gam_cluster_HighIncome > .5 ,1,0)

gam_cluster_cm <- confusionMatrix(as.factor(acs_norm2_test$gam_cluster_HighIncome), as.factor(acs_norm2_test$HighIncome),
                                  positive = "1")

gam_cluster_adjR <- summary(gam_mod_cluster)$r.sq

gam_cluster_aic <- AIC(gam_mod_cluster)

gam_cluster_cm

gam_cluster_adjR

gam_cluster_aic
```

## Second cluster attempt

```{r}
acs_numericals3 <- data.frame(acs$HouseCosts, acs$ElectricBill, acs$Insurance, acs$NumBedrooms, 
                              acs$NumChildren, acs$NumWorkers, acs$NumRooms)

acs_norm3 <- as.data.frame(lapply(acs_numericals3[1:7], normalize))

distance2 <- dist(acs_norm3, method ="euclidean")

pfit2 <- hclust(distance2, method = "ward")

cluster2 <- plot(pfit2)

rect.hclust(pfit2, k=5)

acs_norm3$groups <- cutree(pfit2, k=15)
```

#### Display each goup with number of observations per group

```{r}
table(acs_norm3$groups)
```
## Use groups as new variable in model

```{r}
# Add additional variables ot the data set for model specification
acs_norm3$HighIncome <- c(acs$HighIncome)
acs_norm3$FamilyType <- c(acs$FamilyType)
acs_norm3$Foodstamp <- c(acs$FoodStamp)
acs_norm3$OwnRent <- c(acs$OwnRent)
```

```{r}
# Break it into a training and test set with an 80/20 split.
set.seed(447)
testrecs <- sample(nrow(acs_norm3),0.2 * nrow(acs_norm3))
acs_norm3_test <- acs_norm3[testrecs,]
acs_norm3_fit <- acs_norm3[-testrecs,]  
```


#### Model with clusters

```{r}

gam_mod_cluster2 <- gam(HighIncome ~ s(acs.Insurance) + s(acs.HouseCosts) + s(acs.ElectricBill) + 
                        acs.NumBedrooms + s(acs.NumChildren) + acs.NumWorkers + s(acs.NumRooms) + 
                        FamilyType + Foodstamp + OwnRent + groups, data = acs_norm3_fit, 
                        family=binomial(link="logit"))

summary(gam_mod_cluster2)

acs_norm3_test$gam_cluster_HighIncome <- predict(gam_mod_cluster2, newdata=acs_norm3_test)

acs_norm3_test$gam_cluster_HighIncome <- ifelse(acs_norm3_test$gam_cluster_HighIncome > .5 ,1,0)

gam_cluster_cm2 <- confusionMatrix(as.factor(acs_norm3_test$gam_cluster_HighIncome), as.factor(acs_norm3_test$HighIncome),
                                  positive = "1")

gam_cluster2_adjR <- summary(gam_mod_cluster2)$r.sq

gam_cluster2_aic <- AIC(gam_mod_cluster2)

gam_cluster_cm2

gam_cluster2_adjR

gam_cluster2_aic
```

# Compare both models

```{r}
sprintf("GAM cluster 1: Predicted Accuracy = %.3f Predicted Sensitivity = %.3f AIC = %.1f", 
        gam_cluster_cm$overall['Accuracy'], gam_cluster_cm$byClass['Sensitivity'], gam_cluster_aic)

sprintf("GAM cluster 2: Predicted Accuracy = %.3f Predicted Sensitivity = %.3f AIC = %.1f", 
        gam_cluster_cm2$overall['Accuracy'], gam_cluster_cm2$byClass['Sensitivity'], gam_cluster2_aic)
```
# Cluster Analysis Decision

The groups created via cluster analysis were used as a variable in 2 GAM models

Choose GAM cluster model 2

1) GAM model 2 had higher accuracy, sensitivity, and a lower AIC

2) This is not the best model across all methods used, but comparison of GAM 1 and GAM 2 leads to choosing GAM 2
